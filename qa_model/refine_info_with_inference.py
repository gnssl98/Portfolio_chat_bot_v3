import os
import json
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¡œë”©
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

INPUT_FILE = "info.jsonl"
OUTPUT_FILE = "refined_info.jsonl"

def regenerate_with_inference(data):
    system_prompt = (
        "You are a helpful assistant answering questions about a user's portfolio. "
        "Even if the provided context does not explicitly contain the answer, "
        "you should make a reasonable assumption based on common knowledge or typical patterns."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Context:\n{data['context']}\n\nQuestion:\n{data['question']}"}
    ]

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ë˜ëŠ” gpt-3.5-turbo
            messages=messages,
            temperature=0.9,  # ë” ì°½ì˜ì ì¸ ë‹µë³€ ìœ ë„
        )
        answer = response.choices[0].message.content.strip()
        return answer
    except Exception as e:
        print(f"[ERROR] GPT ì‘ë‹µ ì‹¤íŒ¨: {e}")
        return "ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"

def refine_all():
    refined = []
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        for i, line in enumerate(f):
            try:
                data = json.loads(line.strip())
                print(f"ğŸ”„ ì¬ìƒì„± ì¤‘ ({i+1}) â†’ {data['question']}")
                new_answer = regenerate_with_inference(data)
                data["answer"] = new_answer
                refined.append(data)
            except Exception as e:
                print(f"[ERROR] JSONL ë¼ì¸ íŒŒì‹± ì‹¤íŒ¨: {e}")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for item in refined:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"\nâœ… ì´ {len(refined)} ê°œ í•­ëª© ì¬ìƒì„± ì™„ë£Œ â†’ {OUTPUT_FILE}")

if __name__ == "__main__":
    refine_all()
